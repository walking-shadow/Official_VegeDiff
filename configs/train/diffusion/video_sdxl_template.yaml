model:
  base_learning_rate: 0.0000125 # 1e-4/8=0.0000125    1e-4/64 (32*2 or accumulate 32*4)
  target: sgm.models.diffusion_video.VideoDiffusionEngine
  params:
    scale_factor: 0.13025
    disable_first_stage_autocast: True
    pretrained_image_ckpt: checkpoints/stable-diffusion-xl-base-1.0/sd_xl_base_1.0.safetensors
    input_key: imgs
    log_keys: # TODO
      - txt

    # LR schedule #TODO
    # scheduler_config:
    #   target: sgm.lr_scheduler.LambdaLinearScheduler
    #   params:
    #     warm_up_steps: [ 10000 ]
    #     cycle_lengths: [ 10000000000000 ]
    #     f_start: [ 1.e-6 ]
    #     f_max: [ 1. ]
    #     f_min: [ 1. ]

    # Video SD-XL
    network_config:
      target: sgm.modules.diffusionmodules.models.videomodel.VideoUNetModel
      params:
        adm_in_channels: 2816
        num_classes: sequential
        use_checkpoint: False
        in_channels: 4
        out_channels: 4
        model_channels: 320
        attention_resolutions: [4, 2]
        num_res_blocks: 2
        channel_mult: [1, 2, 4]
        num_head_channels: 64
        use_spatial_transformer: True
        use_linear_in_transformer: True
        transformer_depth: [1, 2, 10]  # note: the first is unused (due to attn_res starting at 2) 32, 16, 8 --> 64, 32, 16
        context_dim: 2048
        spatial_transformer_attn_type: softmax
        # spatial_transformer_attn_type: softmax
        legacy: False
        temporal_module_kwargs:
          num_attention_heads                : 8
          # num_transformer_block              : 1 # now we don't support setting block layer from config
          # attention_block_types              : [ "Temporal_Self", "Temporal_Self" ]
          attention_block_types              : [ "Temporal_Self" ]
          temporal_position_encoding         : true
          temporal_position_encoding_max_len : 24
          temporal_attention_dim_div         : 1
          zero_initialize                    : true
    network_wrapper: sgm.modules.diffusionmodules.wrappers.VideoWrapper
    trainable_modules:
      - "temporal_transformer"
    
    # conditioner config
    conditioner_config:
      target: sgm.modules.GeneralConditioner
      params:
        emb_models:
          # crossattn cond
          - is_trainable: False
            input_key: txt
            ucg_rate: 0.1
            target: sgm.modules.encoders.modules.FrozenCLIPEmbedder
            params:
              layer: hidden
              layer_idx: 11
          # crossattn and vector cond
          - is_trainable: False
            input_key: txt
            ucg_rate: 0.1
            target: sgm.modules.encoders.modules.FrozenOpenCLIPEmbedder2
            params:
              arch: ViT-bigG-14
              version: laion2b_s39b_b160k
              freeze: True
              layer: penultimate
              always_return_pooled: True
              legacy: False
          # vector cond
          - is_trainable: False
            ucg_rate: 0.1
            input_key: original_size_as_tuple
            target: sgm.modules.encoders.modules.ConcatTimestepEmbedderND
            params:
              outdim: 256  # multiplied by two
          # vector cond 
          - is_trainable: False
            ucg_rate: 0.1
            input_key: crop_coords_top_left
            target: sgm.modules.encoders.modules.ConcatTimestepEmbedderND
            params:
              outdim: 256  # multiplied by two
          # vector cond
          - is_trainable: False
            ucg_rate: 0.1
            input_key: target_size_as_tuple
            target: sgm.modules.encoders.modules.ConcatTimestepEmbedderND
            params:
              outdim: 256  # multiplied by two

    # VAE config 
    first_stage_config:
      from_pretrained: stabilityai/sdxl-vae
      target: sgm.models.autoencoder.AutoencoderKLInferenceWrapper
      params:
        embed_dim: 4
        monitor: val/rec_loss
        ddconfig:
          attn_type: vanilla-xformers
          double_z: true
          z_channels: 4
          resolution: 256
          in_channels: 3
          out_ch: 3
          ch: 128
          ch_mult: [1, 2, 4, 4]
          num_res_blocks: 2
          attn_resolutions: []
          dropout: 0.0
        lossconfig:
          target: torch.nn.Identity

    # DM config
    denoiser_config:
      target: sgm.modules.diffusionmodules.denoiser.DiscreteDenoiser
      params:
        num_idx: 1000

        weighting_config:
          target: sgm.modules.diffusionmodules.denoiser_weighting.EpsWeighting
        scaling_config:
          target: sgm.modules.diffusionmodules.denoiser_scaling.EpsScaling
        discretization_config:
          target: sgm.modules.diffusionmodules.discretizer.LegacyDDPMDiscretization

    loss_fn_config: # EDM loss
      target: sgm.modules.diffusionmodules.loss.StandardDiffusionLoss
      params:
        sigma_sampler_config:
          target: sgm.modules.diffusionmodules.sigma_sampling.DiscreteSampling
          params:
            num_idx: 1000

            discretization_config:
              target: sgm.modules.diffusionmodules.discretizer.LegacyDDPMDiscretization

    sampler_config: # EDM Sampler
      target: sgm.modules.diffusionmodules.sampling.EulerEDMSampler
      params:
        num_steps: 50

        discretization_config:
          target: sgm.modules.diffusionmodules.discretizer.LegacyDDPMDiscretization

        guider_config: # CFG guider
          target: sgm.modules.diffusionmodules.guiders.VanillaCFG
          params:
            scale: 7.5

data:
  target: sgm.data.webvid10m.Webvid10MLoader
  params:
    train:
      data_path: s3://infdata/video/
      meta_path: dataset/meta/webvid10m_meta.txt
      clip_length: 16
      clip_FPS_reate: 4
      resize_resolution: [256]
      crop_resolution: [256, 256]
      horizontal_flip: True
      loader:
        batch_size: 1 # 2bs x 32gpu = 64 total_bs
        num_workers: 8
        shuffle: True

lightning:
  strategy:
    target: pytorch_lightning.strategies.DDPStrategy
    params:
      find_unused_parameters: False

  modelcheckpoint:
    save_last_checkpoint:
      params:
        every_n_epochs: 1
        save_last: True

    save_period_checkpoint:
      params:
        every_n_train_steps: 20000
        save_top_k: -1
        monitor: step
        mode: max
        save_last: False

  callbacks:
    video_logger:
      target: sgm.utils.lit_utils.VideoLogger
      params:
        enable_autocast: False
        batch_frequency: 1000
        max_videos: 4
        increase_log_steps: True
        clamp: True

  trainer:
    accumulate_grad_batches: 1
    max_epochs: 20