{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import kornia\n",
    "from videoio_util import *\n",
    "from ceph_util import PetrelBackend\n",
    "\n",
    "loadp=PetrelBackend()\n",
    "reader=PetrelVideoReader(file_client=loadp)\n",
    "x=reader.sample_whole_video(filename=\"s3://infdata/video/webvid10m2/01151/01151223.mp4\")\n",
    "y=reader.sample_clip(clip_length=16, clip_FPS_reate=4, filename=\"s3://infdata/video/webvid10m2/01151/01151223.mp4\")\n",
    "\n",
    "frames_tensor = np.asarray_chkfinite(y['imgs'], dtype=np.uint8)\n",
    "frames_tensor = kornia.image_to_tensor(frames_tensor, keepdim=False)\n",
    "# frames_tensor = kornia.image_to_tensor(frames_tensor, keepdim=False).div(255.0)\n",
    "# print(frames_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def set_proxy(proxy_url):\n",
    "    os.environ['http_proxy'] = proxy_url\n",
    "    os.environ['https_proxy'] = proxy_url\n",
    "\n",
    "def remove_proxy():\n",
    "    if 'http_proxy' in os.environ:\n",
    "        del os.environ['http_proxy']\n",
    "    if 'https_proxy' in os.environ:\n",
    "        del os.environ['https_proxy']\n",
    "\n",
    "# 设置代理\n",
    "proxy_url = 'http://luzeyu:LZYlzy5019339@10.1.11.100:8086'  # 代理服务器的URL，格式为http://ip:port\n",
    "set_proxy(proxy_url)\n",
    "import shutil\n",
    "import kornia\n",
    "from videoio_util import *\n",
    "from ceph_util import PetrelBackend\n",
    "\n",
    "loadp=PetrelBackend()\n",
    "reader=PetrelVideoReader(file_client=loadp)\n",
    "x=reader.sample_whole_video(filename=\"s3://infdata/video/webvid10m0/00001/00001996.mp4\")\n",
    "y=reader.sample_clip(clip_length=16, clip_FPS_reate=4, filename=\"s3://infdata/video/webvid10m0/00001/00001996.mp4\")\n",
    "\n",
    "frames_tensor = np.asarray_chkfinite(y['imgs'], dtype=np.uint8)\n",
    "frames_tensor = kornia.image_to_tensor(frames_tensor, keepdim=False)\n",
    "# frames_tensor = kornia.image_to_tensor(frames_tensor, keepdim=False).div(255.0)\n",
    "# print(frames_tensor)\n",
    "frames_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y['img_shape']\n",
    "import imageio\n",
    "from PIL import Image\n",
    "def numpy_array_to_video(numpy_array, video_out_path, fps=8): #TCHW -> THWC\n",
    "    numpy_array = np.transpose(numpy_array, (0, 2, 3, 1)) #THWC\n",
    "    with imageio.get_writer(video_out_path, fps=fps) as video:\n",
    "        for image in numpy_array:\n",
    "            video.append_data(image)\n",
    "numpy_array_to_video(frames_tensor[:,:,:256,:256].numpy().astype(np.uint8),\"tes1t2.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_array_to_video(frames_tensor.numpy().astype( np.uint8 ),\"test.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_tensor.shape\n",
    "print(frames_tensor.shape)\n",
    "T,C,H,W = frames_tensor.shape\n",
    "frames_tensor_=frames_tensor.view(1,T,C,H,W)\n",
    "import kornia.augmentation as K\n",
    "aug_list = K.VideoSequential(\n",
    "    kornia.augmentation.Resize((256)),\n",
    "    # kornia.augmentation.CenterCrop((256,256)),\n",
    "    kornia.augmentation.RandomHorizontalFlip(p=0.5),\n",
    "    data_format=\"BTCHW\",\n",
    "    same_on_frame=True)\n",
    "output = aug_list(frames_tensor_)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y['total_frames'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ceph_util import PetrelBackend\n",
    "PB = PetrelBackend()\n",
    "x=PB.list_dir_or_file(dir_path=\"s3://infdata/video/webvid10m1\", recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "# x=torchvision.io.read_video(\"s3://infdata/video/webvid10m2/01313/01313442.mp4\")\n",
    "x=PB._client.get(\"s3://infdata/video/webvid10m3/01342/01342302.mp4\")\n",
    "reader=torchvision.io.VideoReader(src=x)\n",
    "reader_md = reader.get_metadata()\n",
    "print(reader_md)\n",
    "frames = []\n",
    "for frame in reader:\n",
    "    frames.append(frame['data'])\n",
    "# print(len(frames))\n",
    "import torch\n",
    "combined_tensor = torch.stack(frames, dim=0) # [3, 336, 596]\n",
    "print(combined_tensor.shape) #TCHW -> RGB 0-255\n",
    "combined_tensor_npz = combined_tensor.numpy()\n",
    "print(type(combined_tensor_npz))\n",
    "print(combined_tensor_npz.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ceph_util import PetrelBackend\n",
    "from sgm.utils.videoio_util import PetrelVideo, numpy_array_to_video\n",
    "PB = PetrelBackend()\n",
    "# x=PB.get_video(filepath=\"s3://infdata/video/webvid10m3/01342/01342301.mp4\")\n",
    "PV = PetrelVideo(file_client=PB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x=PV.sample_clip(filename=\"s3://infdata/video/webvid10m0/00003/00003517.mp4\", clip_length=30, clip_FPS_reate=2)\n",
    "# numpy_array_to_video(numpy_array=x[\"imgs\"], video_out_path=\"test.mp4\", fps=30)\n",
    "x=PV.sample_whole_video(filename=\"s3://infdata/video/webvid10m0/01328/01328813.mp4\")\n",
    "# numpy_array_to_video(numpy_array=x[\"imgs\"], video_out_path=\"test.mp4\", fps=30)\n",
    "print(x['video'].shape)\n",
    "# webvid10m3/00900/00900802"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ceph_util import PetrelBackend\n",
    "from sgm.utils.videoio_util import PetrelVideo, numpy_array_to_video, PetrelDecordReader, PetrelVideoReader\n",
    "PB = PetrelBackend()\n",
    "file = \"webvid10m0/00010/00010501\"\n",
    "PV = PetrelVideoReader(file_client=PB)\n",
    "try:\n",
    "    x=PV.sample_whole_video(filename=\"s3://infdata/video/\"+file+\".mp4\")\n",
    "    print(\"0\")\n",
    "except (RuntimeError, Exception, BaseException, TypeError) as e:\n",
    "    print(e)\n",
    "PV = PetrelDecordReader(file_client=PB)\n",
    "try:\n",
    "    # x=PV.sample_whole_video(filename=\"s3://infdata/video/\"+file+\".mp4\")\n",
    "    x=PV.sample_whole_video(filename=\"s3://infdata/video/\"+file+\".mp4\")\n",
    "    print(\"1\")\n",
    "except (RuntimeError, Exception, BaseException, TypeError) as e:\n",
    "    print(e)\n",
    "PV = PetrelVideo(file_client=PB)\n",
    "try:\n",
    "    x=PV.sample_whole_video(filename=\"s3://infdata/video/\"+file+\".mp4\")\n",
    "    print(\"2\")\n",
    "except (RuntimeError, Exception, BaseException, TypeError) as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(x['imgs'])\n",
    "import numpy as np\n",
    "frames_tensor = np.asarray_chkfinite(x['imgs'], dtype=np.uint8)\n",
    "print(frames_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = []\n",
    "for i in x:\n",
    "    dirs.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_save=[]\n",
    "for path in dirs:\n",
    "    if path.endswith(\".mp4\"):\n",
    "        with open(\"webvid10m1_meta.txt\", \"a+\") as file:\n",
    "            file.write(\"webvid10m1/\"+path[:-4]+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/mnt/petrelfs/luzeyu/workspace/generative-models/sgm/utils/webvid10m0_meta.txt\", \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "lines = [line.strip() for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import torchvision\n",
    "import pytorch_lightning as pl\n",
    "import numpy as np\n",
    "import kornia\n",
    "import kornia.augmentation as K\n",
    "import json\n",
    "import random\n",
    "import torch\n",
    "\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from sgm.utils.videoio_util import *\n",
    "from sgm.utils.ceph_util import PetrelBackend\n",
    "\n",
    "class WebvidDataDictWrapper(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        super().__init__()\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        results = self.dataset[i]\n",
    "        return {\"txt\": results['txt'],\n",
    "                \"imgs\": results['imgs'],\n",
    "                \"original_size_as_tuple\": results['original_size_as_tuple'],\n",
    "                \"crop_coords_top_left\": results['crop_coords_top_left'],\n",
    "                \"target_size_as_tuple\": results['target_size_as_tuple']}\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset.__len__()\n",
    "\n",
    "class Webvid10MDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 data_path, \n",
    "                 meta_path, \n",
    "                 clip_length, \n",
    "                 clip_FPS_reate, \n",
    "                 npzsuffix, \n",
    "                 num_threads=0, \n",
    "                 resize_resolution=(256, 256), \n",
    "                 crop_resolution=(256, 256), \n",
    "                 horizontal_flip=0.5, \n",
    "                 video_reader_choice='original',\n",
    "                 ):\n",
    "        # path\n",
    "        self.data_path = data_path\n",
    "        self.meta_path = meta_path\n",
    "        \n",
    "        self.npzsuffix = npzsuffix\n",
    "        \n",
    "        # augmentation arguments\n",
    "        self.resize_resolution = resize_resolution\n",
    "        self.crop_resolution = crop_resolution\n",
    "        self.horizontal_flip = horizontal_flip\n",
    "        \n",
    "        # sampler arguments\n",
    "        self.clip_length = clip_length\n",
    "        self.clip_FPS_reate = clip_FPS_reate\n",
    "        \n",
    "        # configure petrel-oss and videoreader\n",
    "        self.petrel_backend=PetrelBackend()\n",
    "        self.video_reader_choice = video_reader_choice\n",
    "        if self.video_reader_choice == 'original':\n",
    "            self.video_reader=PetrelVideoReader(file_client=self.petrel_backend)\n",
    "        elif self.video_reader_choice == 'petrel_original':\n",
    "            self.video_reader=PetrelVideo(file_client=self.petrel_backend)\n",
    "        elif self.video_reader_choice == 'petrel_decord':\n",
    "            self.video_reader=PetrelDecordReader(file_client=self.petrel_backend)\n",
    "        # read path list\n",
    "        with open(self.meta_path, \"r\") as file:\n",
    "            self.path_list = file.readlines()\n",
    "        self.path_list = [line.strip() for line in self.path_list]\n",
    "        \n",
    "    def video_aug(self, results, resize_resolution, crop_resolution, horizontal_flip):\n",
    "        frames_tensor = np.asarray_chkfinite(results['imgs'], dtype=np.uint8).transpose(0,3,1,2) #TCHW\n",
    "        # if self.video_reader_choice == 'original' or self.video_reader_choice == 'petrel_decord':\n",
    "        #     frames_tensor = (kornia.image_to_tensor(frames_tensor, keepdim=False)*2.0-255.0).div(255.0)\n",
    "        # elif self.video_reader_choice == 'petrel_original':\n",
    "        #     frames_tensor = (torch.from_numpy(frames_tensor)*2.0-255.0).div(255.0)\n",
    "        # T, C, H, W = frames_tensor.shape# (x*2-255)/255\n",
    "        # frames_tensor_ = frames_tensor.view(1, T, C, H, W)\n",
    "        # # resize, centercrop, horizontalflip\n",
    "        # if len(resize_resolution)==1:\n",
    "        #     resize_resolution = resize_resolution[0]\n",
    "        # aug_list = K.VideoSequential(\n",
    "        #     kornia.augmentation.Resize(resize_resolution),\n",
    "        #     kornia.augmentation.CenterCrop(crop_resolution),\n",
    "        #     kornia.augmentation.RandomHorizontalFlip(p=horizontal_flip),\n",
    "        #     data_format=\"BTCHW\",\n",
    "        #     same_on_frame=True)\n",
    "        # frames_tensor = aug_list(frames_tensor_)\n",
    "        results['imgs'] = frames_tensor\n",
    "        results['img_shape'] = results['imgs'][0].shape\n",
    "        return results\n",
    "    \n",
    "    def get_results(self, idx):\n",
    "        read_path = self.path_list[idx]\n",
    "        video_path = os.path.join(self.data_path, read_path+'.mp4')\n",
    "        json_path = os.path.join(self.data_path, read_path+'.json')\n",
    "        json_data = self.petrel_backend.get_json(filepath=json_path)\n",
    "        results = self.video_reader.sample_whole_video(filename=video_path)\n",
    "        results = self.video_aug(results, self.resize_resolution, self.crop_resolution, self.horizontal_flip)\n",
    "        '''\n",
    "        s3://infdata/video/webvid10m0_npz/00000/00000001\n",
    "            meta.json\n",
    "            0.npz\n",
    "            1.npz\n",
    "        '''\n",
    "        save_dir = os.path.join(self.npzsuffix, \n",
    "                                read_path.split(\"/\")[-3], \n",
    "                                read_path.split(\"/\")[-2], \n",
    "                                read_path.split(\"/\")[-1])\n",
    "        if self.petrel_backend.exists(filepath=os.path.join(save_dir,\"all_frames.npz\")):\n",
    "            self.petrel_backend.remove(filepath=os.path.join(save_dir,\"all_frames.npz\"))\n",
    "        self.petrel_backend.put_npz(filepath=os.path.join(save_dir,\"all_frames.npz\"), value=results['imgs'])\n",
    "        if self.petrel_backend.exists(filepath=os.path.join(save_dir, \"meta.json\")):\n",
    "            self.petrel_backend.remove(filepath=os.path.join(save_dir, \"meta.json\"))\n",
    "        json_data[\"frameinfo\"] = {}\n",
    "        json_data[\"frameinfo\"][\"total_frames\"] = results[\"total_frames\"]\n",
    "        json_data[\"frameinfo\"][\"avg_fps\"] = results['avg_fps']\n",
    "        json_data[\"frameinfo\"][\"img_shape\"] = results['img_shape']\n",
    "        self.petrel_backend.put_json(filepath=os.path.join(save_dir, \"meta.json\"), value=json_data)\n",
    "        \n",
    "        results['img_shape'] = results['imgs'].shape\n",
    "        results['txt'] = json_data[\"caption\"]\n",
    "        results['original_size_as_tuple'] = torch.tensor([0, 0])\n",
    "        results['crop_coords_top_left'] = torch.tensor([results['img_shape'][-2], results['img_shape'][-1]])\n",
    "        results['target_size_as_tuple'] = torch.tensor([results['img_shape'][-2], results['img_shape'][-1]])\n",
    "        return results\n",
    "    \n",
    "    def __len__(self,):\n",
    "        return len(self.path_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        results = {}\n",
    "        if self.video_reader_choice == 'original':\n",
    "            while(True):\n",
    "                try:\n",
    "                    results = self.get_results(idx)\n",
    "                    break\n",
    "                except (RuntimeError, Exception, BaseException) as e:\n",
    "                    print(e, \" : \", self.path_list[idx])\n",
    "                    idx = random.randint(0,self.__len__()-1)\n",
    "        elif self.video_reader_choice == 'petrel_original':\n",
    "            print(self.path_list[idx])\n",
    "            try:\n",
    "                results = self.get_results(idx)\n",
    "            except (RuntimeError, Exception, BaseException, TypeError) as e:\n",
    "                print(e, \" : \", self.path_list[idx])\n",
    "                with open(\"webvid10m_error_meta.txt\", \"a+\") as file:\n",
    "                    file.write(str(self.path_list[idx])+\"\\n\")\n",
    "                results = {\"txt\": \"None\",\n",
    "                           \"imgs\": torch.zeros([self.clip_length, 3, self.crop_resolution[0], self.crop_resolution[1]]),\n",
    "                           \"original_size_as_tuple\": torch.tensor([0, 0]),\n",
    "                           \"crop_coords_top_left\": torch.tensor([0, 0]),\n",
    "                           \"target_size_as_tuple\": torch.tensor([0, 0])}\n",
    "        elif self.video_reader_choice == 'petrel_decord':\n",
    "            print(self.path_list[idx])\n",
    "            try:\n",
    "                results = self.get_results(idx)\n",
    "                results = {\"txt\": \"None\",\n",
    "                           \"imgs\": torch.zeros([self.clip_length, 3, self.crop_resolution[0], self.crop_resolution[1]]),\n",
    "                           \"original_size_as_tuple\": torch.tensor([0, 0]),\n",
    "                           \"crop_coords_top_left\": torch.tensor([0, 0]),\n",
    "                           \"target_size_as_tuple\": torch.tensor([0, 0])}\n",
    "            except (RuntimeError, Exception, BaseException, TypeError) as e:\n",
    "                print(e, \" : \", self.path_list[idx])\n",
    "                results = {\"txt\": \"None\",\n",
    "                           \"imgs\": torch.zeros([self.clip_length, 3, self.crop_resolution[0], self.crop_resolution[1]]),\n",
    "                           \"original_size_as_tuple\": torch.tensor([0, 0]),\n",
    "                           \"crop_coords_top_left\": torch.tensor([0, 0]),\n",
    "                           \"target_size_as_tuple\": torch.tensor([0, 0])}\n",
    "        return results\n",
    "\n",
    "# Full Clip:\n",
    "def init_dataloader(video_reader_choice):\n",
    "    train_dataset = WebvidDataDictWrapper(Webvid10MDataset(\n",
    "                data_path=\"s3://infdata/video/\", \n",
    "                meta_path=\"/mnt/petrelfs/luzeyu/workspace/generative-models/dataset/meta/webvid10m_meta.txt\", \n",
    "                clip_length=16, \n",
    "                clip_FPS_reate=4,\n",
    "                resize_resolution=tuple([256]), \n",
    "                crop_resolution=tuple([256, 256]), \n",
    "                horizontal_flip=0,\n",
    "                video_reader_choice=video_reader_choice,\n",
    "                npzsuffix=\"s3://infdata/video/webvid10m_npz\"\n",
    "                ))\n",
    "    return DataLoader(\n",
    "                train_dataset,\n",
    "                batch_size=16,\n",
    "                num_workers=16,\n",
    "                shuffle=False,\n",
    "                pin_memory=False,\n",
    "                drop_last=False\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sgm.utils.ceph_util import PetrelBackend\n",
    "from sgm.utils.videoio_util import PetrelVideo, numpy_array_to_video, PetrelDecordReader\n",
    "from omegaconf import OmegaConf\n",
    "from sgm.data.webvid10m import Webvid10MLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# PB = PetrelBackend()\n",
    "# conf = OmegaConf.load('configs/train/diffusion/acc_video_sdxl_template.yaml')\n",
    "# webvid_dataloader=Webvid10MLoader(train=conf.data.params.train, video_reader_choice=\"petrel_decord\").test_unit_dataloader()\n",
    "\n",
    "webvid_dataloader=init_dataloader(video_reader_choice=\"petrel_decord\")\n",
    "\n",
    "idx=0\n",
    "print(\"debug start\")\n",
    "for i in tqdm(webvid_dataloader):\n",
    "    print(idx)\n",
    "    idx+=1\n",
    "    x=i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "err: 1761\n",
      "normal: 10727580\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[39mif\u001b[39;00m path \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m err_path_list:\n\u001b[1;32m     17\u001b[0m         length_clean \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m---> 18\u001b[0m         \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mwebvid10m_meta_clean.txt\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39ma+\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m     19\u001b[0m             f\u001b[39m.\u001b[39mwrite(path\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     20\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mlength_clean\u001b[39m\u001b[39m\"\u001b[39m, length_clean)\n",
      "File \u001b[0;32m~/anaconda3/envs/gen-torch2/lib/python3.9/site-packages/IPython/core/interactiveshell.py:286\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[1;32m    280\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    281\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    283\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    284\u001b[0m     )\n\u001b[0;32m--> 286\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/gen-torch2/lib/python3.9/_bootlocale.py:33\u001b[0m, in \u001b[0;36mgetpreferredencoding\u001b[0;34m(do_setlocale)\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[39mreturn\u001b[39;00m locale\u001b[39m.\u001b[39mgetpreferredencoding(do_setlocale)\n\u001b[1;32m     32\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 33\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mgetpreferredencoding\u001b[39m(do_setlocale\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m     34\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m do_setlocale\n\u001b[1;32m     35\u001b[0m         \u001b[39mif\u001b[39;00m sys\u001b[39m.\u001b[39mflags\u001b[39m.\u001b[39mutf8_mode:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "with open(\"/mnt/petrelfs/luzeyu/workspace/generative-models/dataset/meta/webvid10m_error_meta.txt\", \"r\") as file:\n",
    "    err_path_list = file.readlines()\n",
    "err_path_list = [line.strip() for line in err_path_list]\n",
    "\n",
    "with open(\"/mnt/petrelfs/luzeyu/workspace/generative-models/dataset/meta/webvid10m_meta.txt\", \"r\") as file:\n",
    "    path_list = file.readlines()\n",
    "path_list = [line.strip() for line in path_list]\n",
    "\n",
    "print(\"err:\", len(err_path_list))\n",
    "print(\"normal:\", len(path_list))\n",
    "\n",
    "length_clean = 0\n",
    "for path in path_list:\n",
    "    if path not in err_path_list:\n",
    "        length_clean += 1\n",
    "        with open(\"webvid10m_meta_clean.txt\", \"a+\") as f:\n",
    "            f.write(path+\"\\n\")\n",
    "print(\"length_clean\", length_clean)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen-torch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
